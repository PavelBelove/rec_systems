{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теоретическая часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Вспомним прошлый вебинар, мы рассматривали User-User рекомендации и Item-Item рекомендации. Чем они отличаются и чем они похожи? Если есть функция item_item_rec(interaction_matrix). Можно ли использовать эту функцию для user_user_rec?  \n",
    "В чем принципиальные отличия item-item рекомендаций от ALS?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С точки зрения математики, item_item и user_user идентичны. Различаются \"направлением\" данных, что у нас представляет столбец в датафрейме - товар, либо пользователя. Другими словами, если единственным действием для преобразования одного алгоритма в другой, будет транспонирование исходной матрицы. \n",
    "\n",
    "Что до различия с точки зрения бизнеса, user_user будет хорошо отрабатывать для \"постоянного\" клиента, о котором уже собраны данные. Плохо - для нового. На покойном ныне Имхонете, судя по всему, применялся этот подход. item_item - наоборот, мало учитывает персонификацию, и предлагает товары на основе \"похожести\", \"совместных покупок\", новые товары по этой логике будут непопулярны.\n",
    "\n",
    "ALS, в отличие от предыдущих двух алгоритмов, разбивает большую разреженную матрицу на две \"узких\", экономя место для хранения данных. Поиск минимума среднеквадратичной ошибки ведется по ним. Вернее, алгоритм \"фиксирует\" один из параметров (пользователей), и ищет оптимальные товары."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Приведите 3 примера весов (те, которых не было на вебинаре: сумма покупок, количество покупок - неинтересно) user-item матрицы для задачи рекомендаций товаров \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Фактор \"новизны\". Например, T/t, где T - гиперпараметр, кол-во дней. t - кол-во дней с момента появления товара в магазине.\n",
    "* Сезонность. Довольно глупо рекоммендовать лыжи в середине весны.\n",
    "* кол-во покупок товаров \"из той же категории\" - для этого потребуется \"подтянуть\" данные о товарах, группировать по категориям и считать суммарное кол-во покупок. Но если пользователь купил уже пять квадрокоптеров, тема его явно \"цепляет\", и нужно для этого юзера всем коптерам установить высокий вес. Изначально же этого не видно - все куплены в единственном экземпляре, и никак не отличимы, например, от единственного фотоаппарата, купленного тем же пользователем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Какие ограничения есть у ALS? (Тип информации, линейность/нелинейность факторов и т д)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Трафик. Своеобразная \"цена\" за сжатость данных.\n",
    "2. Считает лишь факт взаимодействия пользователя с товаром. Некоторые элементы очень популярны, они получат неоправданно высокое \"внимание\" и кол-во выделенной памяти.\n",
    "3. Минимизирует квадрат потерь - не всегда это оптимально."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Мы рассматривали bm_25_weight. \n",
    "Опишите, как он работает. Как сделать рекомендации только на основе bm_25? (Можно и нужно пользоваться любыми источниками, приложите на них ссылки). Какие еще способы перевзвешивания user-item матрицы Вы знаете / можете предложить (ещё 2-3 способа)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм оперирует параметром \"встречаемости\". Например, молоко покупают очень многие люди. Но это как раз снижает \"ценность\" продукта для рекоммендации. Мы бы хотели делать это персонально, и сводить клиента с интересующими его товарами, а не просто \"впаривать\" то, что покупается по-определению.\n",
    "\n",
    "Если мы разделим q(m) (пользователи, покупающие молоко) на общее кол-во пользователей N - получим \"вероятность\" товара быть случайно купленным.\n",
    "Чем меньше это число, тем более \"уникальный\" товар, и он лучше характеризует пользователя. Чтобы получить зависимость \"чем больше тем больше\", перевернем дробь N/q(m).\n",
    "\n",
    "Чтобы сгладить кривую, и не \"возносить до небес\" редкие товары, возьмем логарифм. $\\lg{\\frac{N}{q(m)}}$\n",
    "\n",
    "Итоговая вероятность того, что пользователь купил несколько разных товаров, будет равна произведению вероятностей покупки каждого из них. Поскольку вероятности у нас под логарифмом, будет сумма логарифмов.\n",
    "$$\\sum_{i=1}^n\\lg{\\frac{N}{q(m_i)}}$$\n",
    "\n",
    "Это упрощенная реализация IDF в bm_25_weight. Именно тот механизм, который помогает перевзвесить матрицу, с учетом \"уникальности запросов\". Если юзер покупает зеркалку Кодак и объективы к нему, то это - не случайность, тогда как хлеб и молоко - распространенная \"пара\", и потому менее ценная для предсказаний.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практическая часть\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.nearest_neighbours import bm25_weight, tfidf_weight\n",
    "\n",
    "# Функции из 1-ого вебинара\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from implicit.evaluation import precision_at_k\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "# utils functions like in webinar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор матрицы $c_{ui}$\n",
    "Попробуйте различные варианты матрицы весов (3+ вариантов). Обучите алгоритм для различных $C$. В качестве результата приведите таблицу: матрица весов - результат на train и validation.\n",
    "Сделате качественные выводы.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимизация гипперпараметров\n",
    "Для лучшей матрицы весов из первого задания подберите оптимальные $\\lambda$ и n_factors. Подбор можно делать вручную (цикл в цикле, аналог sklearn.GridSearch, или случайно - sklearn.GridSearch). Или Вы можете воспользоваться библиотеками для автоматического подбора гипперпараметров (любые на Ваш вкус). В качестве результата постройте графики:\n",
    "1. Значение параметра - время обучения \n",
    "2. Значение параметра - качество train, качество validation  \n",
    "\n",
    "Сделайте качественные выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P.S.** Не пишите отписки в качестве выводов. Мне интресены Ваши рассуждения, трудности, с которыми Вы сталкнулись и что-то, что Вас удивило. Если выводы контринтуитивны - напишите об этом, в этом нет ничего страшного!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
