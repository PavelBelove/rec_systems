{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - В чем принципиальное отличие гибридных рекомендательных систем от коллаборативной филтьтрации?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гибридные системы, помимо матрицы взаимодействий юзеров и товаров, \"подтягивают\" дополнительные данные о пользователях и (или) товарах. Поскольку для предсказаний используются дополнительные фичи, гибридная РС \"владеет\" куда более полной информацией, чем коллаборативная фильтрация. Ценой за это будет усложнение модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Приведите 2-3 примера задач, в которых необходимо использовать гибридные системы\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главным плюсом гибридных систем перед коллаборативными, будет более легкий \"холодный старт\". Поскольку система оперирует бОльшим объемом данных, отсутствие взаимодействия пользователя и товара не является \"нулем\" - присутствуют дополнительные сведения, позволяющие сделать рекоммендацию на основе \"похожести\". Если в нашу систему постоянно добавляются товары/ новые пользователи - имеет смысл использовать гибридную систему. Пример - большинство интернет-магазинов.\n",
    "\n",
    "\n",
    "Другой сильной стороной гибридных систем является способность учитывать специфику.\n",
    "\n",
    "Как юзера: возраст, гендер, регион, семейное положение и т.д.\n",
    "\n",
    "Так и товара: тематика/жанры, сезонность, ценовой сегмент.\n",
    "\n",
    "Например, если у нас \"магазин всего\", товары в нем разбиты по категориям, и гибридная система с большей вероятностью предлагала бы пользователю, купившему шуруповерт и мастерок, товары из категорий \"ремонт\" и \"инструменты\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прочитайте статью про поиск на hh.ru https://habr.com/ru/company/hh/blog/347276/\n",
    "Нам интересна именно рекомендательная система, раздел \"Производительность системы\" можно пропустить\n",
    "Какие основные отличия предложенной системы от тех подходов, которые мы разбирали на семинарах? Какие проблемы могут возникнуть при выводе такой модели в продакшен?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ключевым отличием системы рекоммендаций hh.ru от подходов, применяемых нами, будет многоступенчатость процесса. Фактически, реализованные там РС представляют каскад из моделей, причем сначала данные подаются на простые, не ресурсоемкие модели, где отсеиваются явно неподходящие вакансии. Тот же объем, что был \"рекомендован\" простыми моделями подается на более сложные и ресурсоемкие. Фактически, реализация \"воронки продаж\" в виде каскада моделей.\n",
    "\n",
    "По сложностям - задавался этим вопросом еще во время 1-го ДЗ: Сайт hh зарабатывает в том числе и помощью платных размещений вакансий. Естественно, деньги работодателем платятся за премиум-возможности, но это прямо противоречит интересам соискателей (непосредственные пользователи системы). Необходимо найти очень тонкий баланс, чтобы соискателю на \"аналитика\" не выдавались вакансии \"менеджера\" из-за того, что они премиум, но в то же время чтобы те, кто оплачивает \"премиум\" оставались в выигрыше.\n",
    "\n",
    "В статье описано одно из решений этой проблемы: Модели составляют рейтинг для платных вакансий, и примешивают к нему бесплатные, с максимальной вероятностью отклика. Остальные вакансии ранжируются по порядку.\n",
    "\n",
    "Другая сложность - огромное количество пустых поисковых запросов, особенно от незарегистрированных пользователей. для обработки которых, фактически, была сделана отдельная РС"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### На вебинаре мы рассматривали модель LightFM (https://making.lyst.com/lightfm/docs/lightfm.html). В работе Data Scientist'а важную часть занимает research - исследование существующих архитектур и разбор научных статей, в которых они описываются. Вам предлагается изчуть оригинальную статью про LightFM https://arxiv.org/pdf/1507.08439.pdf и ответить на следующие вопросы:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Какой датасет используют авторы?\n",
    "\n",
    "\n",
    "Авторы используют для тестирования два датасета MovieLens 10M содержит 69878 пользователей, 10681 элемент, 9996948 взаимодействий и 1030 уникальных тегов. - это \"плотные\" данные о взаимодействии пользователей с фильмами.\n",
    "\n",
    "Второй датасет - CrossValidated Набор данных состоит из 5953 пользователей,\n",
    "44 200 вопросов и 188 865 ответов и комментариев. Каждый вопрос сопровождается одним или несколькими из 1032 уникальных тегов. Эти данные более разрежены.\n",
    "\n",
    "#### 2) Что используют в качестве признаков?\n",
    "\n",
    "MovieLens - Список жанров и список тэгов фильма, рейтинг точности тега к фильму, оценки пользователей.\n",
    "\n",
    "CrossValidated - Вопросы и ответы пользователей.\n",
    "\n",
    "#### 3) С какими моделями сравнивают LightFM? Опишите их основные идеи кратко\n",
    "\n",
    "collaborative MF: обычная матричная факторизационная модель с сигмоидной функцией.\n",
    "\n",
    "LSI-LR - контентно-ориентированная модель. Под капотом логистическая регрессия для каждого пользователя. Основывается на факторизации матрицы контента.\n",
    "\n",
    "LSI-UP: гибридная модель, представляющая профили пользователей (UP) в виде линейных комбинаций векторов содержимого элементов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть внешние данные. Что с ними не так? Чего не хватает?\n",
    "\n",
    "Проведите исследование внешних данных и составьте какие-нибудь содержательные выводы.\n",
    "Формально Вам нужно построить 3+ графиков (scatter plot, hist или что-то иное) и описать, что мы видим (например, товары такой-то категории болле часто покупаются в следующие дни недели или пользователи с большим достатком предпочитают такие-то товары).\n",
    "Исследуйте те закономерности, которые Вам интересно, чем менее тривиальный вывод получается, тем лучше!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightFM\n",
    "\n",
    "У этого алогритма есть множество параметров (item/user_alpha, loss, no_components).\n",
    "Проведите эксперименты аналогично дз 3 (подберите гипперпараметры каким удобно способои и постройте графики)\n",
    "На выходе необходимо получить pr@5 на валидации (последние 3 недели) > 17%\n",
    "У Вас, скорее всего, возникнет проблема со временем обучения. Попробуйте запустить алгоритм вообще без фичей или используйте только признаки с небольшим числом уникальных категорий. (item_features['commodity_desc'].unique() - 300 уникальных категорий - это очень много)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k as pr\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.nearest_neighbours import bm25_weight, tfidf_weight\n",
    "\n",
    "# Функции из 1-ого вебинара\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from implicit.evaluation import precision_at_k\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.metrics import precision_at_k, recall_at_k\n",
    "from src.utils import prefilter_items\n",
    "from src.recommenders import MainRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1004906</td>\n",
       "      <td>1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1033142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "0     2375  26984851472    1  1004906         1         1.39       364   \n",
       "1     2375  26984851472    1  1033142         1         0.82       364   \n",
       "\n",
       "   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "0         -0.6        1631        1          0.0                0.0  \n",
       "1          0.0        1631        1          0.0                0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/retail_train.csv')\n",
    "item_features = pd.read_csv('data/product.csv')\n",
    "user_features = pd.read_csv('data/hh_demographic.csv')\n",
    "\n",
    "# column processing\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
    "\n",
    "# train test split\n",
    "test_size_weeks = 3\n",
    "\n",
    "data_train = data[data['week_no'] < data['week_no'].max() - test_size_weeks]\n",
    "data_test = data[data['week_no'] >= data['week_no'].max() - test_size_weeks]\n",
    "\n",
    "data_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual</th>\n",
       "      <th>random_recommendation</th>\n",
       "      <th>popular_recommendation</th>\n",
       "      <th>itemitem</th>\n",
       "      <th>cosine</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>own_purchases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[821867, 834484, 856942, 865456, 889248, 90795...</td>\n",
       "      <td>[846312, 9823000, 900243, 10309250, 588311]</td>\n",
       "      <td>[6534178, 6533889, 1029743, 6534166, 1082185]</td>\n",
       "      <td>[999999, 1082185, 981760, 1127831, 995242]</td>\n",
       "      <td>[1082185, 999999, 981760, 1127831, 1098066]</td>\n",
       "      <td>[1082185, 981760, 1127831, 999999, 1098066]</td>\n",
       "      <td>[999999, 1082185, 1029743, 995785, 1004906]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[835476, 851057, 872021, 878302, 879948, 90963...</td>\n",
       "      <td>[13511611, 1021529, 928537, 956887, 908361]</td>\n",
       "      <td>[6534178, 6533889, 1029743, 6534166, 1082185]</td>\n",
       "      <td>[999999, 1082185, 981760, 1098066, 995242]</td>\n",
       "      <td>[1082185, 1098066, 981760, 999999, 826249]</td>\n",
       "      <td>[1082185, 981760, 1098066, 826249, 999999]</td>\n",
       "      <td>[999999, 1082185, 1098066, 6534178, 1127831]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                             actual  \\\n",
       "0        1  [821867, 834484, 856942, 865456, 889248, 90795...   \n",
       "1        3  [835476, 851057, 872021, 878302, 879948, 90963...   \n",
       "\n",
       "                         random_recommendation  \\\n",
       "0  [846312, 9823000, 900243, 10309250, 588311]   \n",
       "1  [13511611, 1021529, 928537, 956887, 908361]   \n",
       "\n",
       "                          popular_recommendation  \\\n",
       "0  [6534178, 6533889, 1029743, 6534166, 1082185]   \n",
       "1  [6534178, 6533889, 1029743, 6534166, 1082185]   \n",
       "\n",
       "                                     itemitem  \\\n",
       "0  [999999, 1082185, 981760, 1127831, 995242]   \n",
       "1  [999999, 1082185, 981760, 1098066, 995242]   \n",
       "\n",
       "                                        cosine  \\\n",
       "0  [1082185, 999999, 981760, 1127831, 1098066]   \n",
       "1   [1082185, 1098066, 981760, 999999, 826249]   \n",
       "\n",
       "                                         tfidf  \\\n",
       "0  [1082185, 981760, 1127831, 999999, 1098066]   \n",
       "1   [1082185, 981760, 1098066, 826249, 999999]   \n",
       "\n",
       "                                  own_purchases  \n",
       "0   [999999, 1082185, 1029743, 995785, 1004906]  \n",
       "1  [999999, 1082185, 1098066, 6534178, 1127831]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.read_csv('data/predictions_basic.csv')\n",
    "result.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>department</th>\n",
       "      <th>brand</th>\n",
       "      <th>commodity_desc</th>\n",
       "      <th>sub_commodity_desc</th>\n",
       "      <th>curr_size_of_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25671</td>\n",
       "      <td>2</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>FRZN ICE</td>\n",
       "      <td>ICE - CRUSHED/CUBED</td>\n",
       "      <td>22 LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26081</td>\n",
       "      <td>2</td>\n",
       "      <td>MISC. TRANS.</td>\n",
       "      <td>National</td>\n",
       "      <td>NO COMMODITY DESCRIPTION</td>\n",
       "      <td>NO SUBCOMMODITY DESCRIPTION</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  manufacturer    department     brand            commodity_desc  \\\n",
       "0    25671             2       GROCERY  National                  FRZN ICE   \n",
       "1    26081             2  MISC. TRANS.  National  NO COMMODITY DESCRIPTION   \n",
       "\n",
       "            sub_commodity_desc curr_size_of_product  \n",
       "0          ICE - CRUSHED/CUBED                22 LB  \n",
       "1  NO SUBCOMMODITY DESCRIPTION                       "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_desc</th>\n",
       "      <th>marital_status_code</th>\n",
       "      <th>income_desc</th>\n",
       "      <th>homeowner_desc</th>\n",
       "      <th>hh_comp_desc</th>\n",
       "      <th>household_size_desc</th>\n",
       "      <th>kid_category_desc</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65+</td>\n",
       "      <td>A</td>\n",
       "      <td>35-49K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45-54</td>\n",
       "      <td>A</td>\n",
       "      <td>50-74K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age_desc marital_status_code income_desc homeowner_desc      hh_comp_desc  \\\n",
       "0      65+                   A      35-49K      Homeowner  2 Adults No Kids   \n",
       "1    45-54                   A      50-74K      Homeowner  2 Adults No Kids   \n",
       "\n",
       "  household_size_desc kid_category_desc  user_id  \n",
       "0                   2      None/Unknown        1  \n",
       "1                   2      None/Unknown        7  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исправим строковые признаки, которые легко выражаются численно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features['age_desc'] = user_features['age_desc'].apply(lambda x: int(x[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['35-49K', '50-74K', '25-34K', '75-99K', 'Under 15K', '100-124K',\n",
       "       '15-24K', '125-149K', '150-174K', '250K+', '175-199K', '200-249K'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features['income_desc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features['income_desc'] = user_features['income_desc'].apply(\\\n",
    "                    lambda x: 5 if x=='Under 15K' else (int(x[:2] if x[2]=='-' else x[:3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decreased # items from 86865 to 2489\n"
     ]
    }
   ],
   "source": [
    "n_items_before = data_train['item_id'].nunique()\n",
    "\n",
    "data_train = prefilter_items(data_train, item_features)\n",
    "\n",
    "n_items_after = data_train['item_id'].nunique()\n",
    "print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заведем фиктивный item_id (если юзер покупал товары из топ-5000, то он \"купил\" такой товар)\n",
    "#data_train.loc[~data_train['item_id'].isin(top_5000), 'item_id'] = 999999 - уже сделано в src\n",
    "\n",
    "user_item_matrix = pd.pivot_table(data_train, \n",
    "                                  index='user_id', columns='item_id', \n",
    "                                  values='quantity', # Можно пробоват ьдругие варианты\n",
    "                                  aggfunc='count', \n",
    "                                  fill_value=0\n",
    "                                 )\n",
    "\n",
    "user_item_matrix = user_item_matrix.astype(float) # необходимый тип матрицы для implicit\n",
    "\n",
    "# переведем в формат sparse matrix\n",
    "sparse_user_item = csr_matrix(user_item_matrix).tocsr()\n",
    "\n",
    "# user_item_matrix.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test = data_test[data_test['item_id'].isin(data_train['item_id'].unique())]\n",
    "test_user_item_matrix = pd.pivot_table(data_test, \n",
    "                                  index='user_id', columns='item_id', \n",
    "                                  values='quantity', # Можно пробоват ьдругие варианты\n",
    "                                  aggfunc='count', \n",
    "                                  fill_value=0\n",
    "                                 )\n",
    "\n",
    "test_user_item_matrix = user_item_matrix.astype(float) # необходимый тип матрицы для implicit\n",
    "\n",
    "# переведем в формат sparse matrix\n",
    "test_sparse_user_item = csr_matrix(test_user_item_matrix).tocsr()\n",
    "\n",
    "# test_user_item_matrix.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    2,    3, ..., 2498, 2499, 2500])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# словари перенормировки индексов\n",
    "\n",
    "userids = user_item_matrix.index.values\n",
    "itemids = user_item_matrix.columns.values\n",
    "\n",
    "matrix_userids = np.arange(len(userids))\n",
    "matrix_itemids = np.arange(len(itemids))\n",
    "\n",
    "id_to_itemid = dict(zip(matrix_itemids, itemids))\n",
    "id_to_userid = dict(zip(matrix_userids, userids))\n",
    "\n",
    "itemid_to_id = dict(zip(itemids, matrix_itemids))\n",
    "userid_to_id = dict(zip(userids, matrix_userids))\n",
    "\n",
    "userids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_desc</th>\n",
       "      <th>marital_status_code</th>\n",
       "      <th>income_desc</th>\n",
       "      <th>homeowner_desc</th>\n",
       "      <th>hh_comp_desc</th>\n",
       "      <th>household_size_desc</th>\n",
       "      <th>kid_category_desc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.0</td>\n",
       "      <td>A</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age_desc marital_status_code  income_desc homeowner_desc  \\\n",
       "user_id                                                             \n",
       "1            65.0                   A         35.0      Homeowner   \n",
       "2             NaN                 NaN          NaN            NaN   \n",
       "\n",
       "             hh_comp_desc household_size_desc kid_category_desc  \n",
       "user_id                                                          \n",
       "1        2 Adults No Kids                   2      None/Unknown  \n",
       "2                     NaN                 NaN               NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_feat = pd.DataFrame(user_item_matrix.index)\n",
    "user_feat = user_feat.merge(user_features, on='user_id', how='left')\n",
    "user_feat.set_index('user_id', inplace=True)\n",
    "\n",
    "item_feat = pd.DataFrame(user_item_matrix.columns)\n",
    "item_feat = item_feat.merge(item_features, on='item_id', how='left')\n",
    "item_feat.set_index('item_id', inplace=True)\n",
    "\n",
    "user_feat.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat_lightfm = pd.get_dummies(user_feat, columns=user_feat.columns.tolist())\n",
    "item_feat_lightfm = pd.get_dummies(item_feat, columns=item_feat.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f4786c20100>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(no_components=5,\n",
    "                loss='bpr', # 'warp'\n",
    "                learning_rate=0.05, \n",
    "                item_alpha=0.1, user_alpha=0.1, \n",
    "                random_state=42)\n",
    "\n",
    "model.fit((sparse_user_item > 0) * 1,  # user-item matrix из 0 и 1\n",
    "          sample_weight=coo_matrix(user_item_matrix),\n",
    "          user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "          item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "          epochs=15, \n",
    "          num_threads=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_emb = model.get_user_representations(\n",
    "    features=csr_matrix(user_feat_lightfm.values).tocsr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_emb = model.get_item_representations(\n",
    "    features=csr_matrix(item_feat_lightfm.values).tocsr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00051001, -0.00124938,  0.00170211, -0.00463589,  0.00206194],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.00348423, -0.00519804,  0.0030353 , -0.00454931,  0.00100405],\n",
       "       [-0.00600547,  0.01124585, -0.0031172 ,  0.00069581,  0.00498911],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_emb[1]  # embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LightFM.predict of <lightfm.lightfm.LightFM object at 0x7f4786c20100>>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2352141"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pr = precision_at_k\n",
    "train_precision = pr(model, sparse_user_item, \n",
    "                                 user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                 item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                 k=5).mean()\n",
    "\n",
    "train_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.05, 0.1, 0.2]\n",
    "item_alpha = [0.1, 0.5, 1, 2]\n",
    "user_alpha = [0.05, 0.1, 0.2]\n",
    "no_components = [3, 5, 7, 10]\n",
    "\n",
    "best_pr = 0\n",
    "report_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "best params\n",
      "test_precision = 0.34613850712776184 train_precision = 0.34613850712776184 \n",
      " no_components=3 learning_rate=0.1, item_alpha=0.1, user_alpha=0.05 \n"
     ]
    }
   ],
   "source": [
    "for no_comp in no_components:\n",
    "    for l_rate in learning_rate:\n",
    "        for i_alpha in item_alpha:\n",
    "            for u_alpha in user_alpha:\n",
    "                model = LightFM(no_components=no_comp,\n",
    "                    loss='warp', #'bpr'\n",
    "                    learning_rate=l_rate, \n",
    "                    item_alpha=i_alpha, user_alpha=u_alpha, \n",
    "                    random_state=42)\n",
    "\n",
    "                model.fit((sparse_user_item > 0) * 1,  # user-item matrix из 0 и 1\n",
    "                          sample_weight=coo_matrix(user_item_matrix),\n",
    "                          user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                          item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                          epochs=15, \n",
    "                          num_threads=4) \n",
    "\n",
    "                train_precision = pr(model, sparse_user_item, \n",
    "                                                 user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                                 item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                                 k=5).mean()\n",
    "    \n",
    "                test_precision = pr(model, test_sparse_user_item, \n",
    "                                                 user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                                 item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                                 k=5).mean()\n",
    "\n",
    "                report = f'test_precision = {test_precision} train_precision = {train_precision} \\n no_components={no_comp} learning_rate={l_rate}, item_alpha={i_alpha}, user_alpha={u_alpha} '\n",
    "                report_list.append(report)\n",
    "                if test_precision > best_pr:\n",
    "                    best_report = report\n",
    "                    best_pr = test_precision\n",
    "\n",
    "#                 print(report)\n",
    "\n",
    "print('*'*10)\n",
    "print('best params')\n",
    "print(best_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_precision = 0.34613850712776184 train_precision = 0.34613850712776184 \n",
      " no_components=7 learning_rate=0.1, item_alpha=0.1, user_alpha=0.1 \n",
      "test_precision = 0.34613850712776184 train_precision = 0.34613850712776184 \n",
      " no_components=5 learning_rate=0.2, item_alpha=0.1, user_alpha=0.1 \n",
      "test_precision = 0.34613850712776184 train_precision = 0.34613850712776184 \n",
      " no_components=5 learning_rate=0.1, item_alpha=0.1, user_alpha=0.2 \n",
      "test_precision = 0.34613850712776184 train_precision = 0.34613850712776184 \n",
      " no_components=3 learning_rate=0.2, item_alpha=0.1, user_alpha=0.2 \n",
      "test_precision = 0.34613850712776184 train_precision = 0.34613850712776184 \n",
      " no_components=3 learning_rate=0.2, item_alpha=0.1, user_alpha=0.1 \n",
      "test_precision = 0.34613850712776184 train_precision = 0.34613850712776184 \n",
      " no_components=3 learning_rate=0.1, item_alpha=0.5, user_alpha=0.1 \n",
      "test_precision = 0.34613850712776184 train_precision = 0.34613850712776184 \n",
      " no_components=3 learning_rate=0.1, item_alpha=0.1, user_alpha=0.2 \n",
      "test_precision = 0.34613850712776184 train_precision = 0.34613850712776184 \n",
      " no_components=3 learning_rate=0.1, item_alpha=0.1, user_alpha=0.1 \n",
      "test_precision = 0.34613850712776184 train_precision = 0.34613850712776184 \n",
      " no_components=3 learning_rate=0.1, item_alpha=0.1, user_alpha=0.05 \n"
     ]
    }
   ],
   "source": [
    "count = 9\n",
    "for i in sorted(report_list, reverse = True):\n",
    "    print(i)\n",
    "    count -= 1\n",
    "    if count == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
